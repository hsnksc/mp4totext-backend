# ğŸ¯ MP4toText - Scalable Architecture Quick Start

## âœ… Tamamlanan YapÄ±landÄ±rma

### ğŸ“ Yeni Dosya YapÄ±sÄ±

```
mp4totext-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config/                      # âœ¨ YENÄ° - Environment-based config
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                 # Base configuration
â”‚   â”‚   â”œâ”€â”€ development.py          # Dev: 2 workers
â”‚   â”‚   â”œâ”€â”€ staging.py              # Staging: 4-6 workers
â”‚   â”‚   â””â”€â”€ production.py           # Prod: 8-12 workers
â”‚   â”‚
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”œâ”€â”€ tasks/                  # âœ¨ YENÄ° - Priority-based tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ critical.py        # Upload, file ops (priority=10)
â”‚   â”‚   â”‚   â”œâ”€â”€ high_priority.py   # Transcription (priority=7)
â”‚   â”‚   â”‚   â”œâ”€â”€ default_priority.py # AI enhancement (priority=5)
â”‚   â”‚   â”‚   â””â”€â”€ low_priority.py    # Cleanup (priority=2)
â”‚   â”‚   â””â”€â”€ transcription_worker.py # Mevcut worker
â”‚   â”‚
â”‚   â””â”€â”€ utils/                      # âœ¨ YENÄ° - Monitoring
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ monitoring.py           # Task metrics, health checks
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ load_test.py               # âœ¨ YENÄ° - 1000 user load test
â”‚
â”œâ”€â”€ docker-compose.dev.yml         # Mevcut (dev environment)
â”œâ”€â”€ docker-compose.prod.yml        # âœ¨ YENÄ° - Production with scaling
â”œâ”€â”€ .env.development              # âœ¨ YENÄ° - Dev environment vars
â”œâ”€â”€ .env.production               # âœ¨ YENÄ° - Prod environment vars
â””â”€â”€ DEPLOYMENT_GUIDE.md           # âœ¨ YENÄ° - KapsamlÄ± deployment rehberi
```

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Development Mode

```bash
# Backend klasÃ¶rÃ¼nde
cd mp4totext-backend

# Environment variables (API keys ekle)
cp .env.development .env

# Manuel baÅŸlatma
python run.py                                    # Terminal 1: Backend
redis-server                                      # Terminal 2: Redis
celery -A app.celery_app worker -l info         # Terminal 3: Worker
celery -A app.celery_app flower                 # Terminal 4: Monitoring

# VEYA Docker ile (Ã–nerilen)
docker-compose -f docker-compose.dev.yml up -d

# Flower Monitoring UI
http://localhost:5555
```

### 2. Production Mode (1000 KullanÄ±cÄ± iÃ§in)

```bash
# Production environment ayarla
cp .env.example .env.production
# .env.production dosyasÄ±nÄ± dÃ¼zenle (gÃ¼venlik ayarlarÄ±)

# Docker ile baÅŸlat
docker-compose -f docker-compose.prod.yml up -d

# Worker kapasitesi:
# - 3 replica Ã— 6 = 18 critical workers (upload)
# - 5 replica Ã— 12 = 60 high workers (transcription)
# - 4 replica Ã— 10 = 40 default workers (AI enhancement)
# - 1 replica Ã— 4 = 4 low workers (cleanup)
# TOPLAM: 122 concurrent workers

# Scale up if needed
docker-compose -f docker-compose.prod.yml up -d --scale celery_worker_high=10
```

---

## ğŸ“Š Priority-Based Queue Sistemi

### Queue YapÄ±sÄ±

| Queue | Priority | Ä°ÅŸlemler | Worker SayÄ±sÄ± (Prod) |
|-------|----------|----------|----------------------|
| **critical** | 10 | Upload, File validation, Real-time ops | 18 (3Ã—6) |
| **high** | 7 | Whisper transcription, Speaker recognition | 60 (5Ã—12) |
| **default** | 5 | AI enhancement, Translation, Lecture notes | 40 (4Ã—10) |
| **low** | 2 | Cleanup, Maintenance, Batch operations | 4 (1Ã—4) |

### Otomatik Task Routing

```python
# Task'lar otomatik olarak doÄŸru queue'ya yÃ¶nlendirilir:

# app/config/base.py'de tanÄ±mlÄ±:
'task_routes': {
    'app.workers.tasks.upload.*': {'queue': 'critical'},
    'app.workers.process_transcription': {'queue': 'high'},
    'app.workers.tasks.ai_enhancement.*': {'queue': 'default'},
    'app.workers.tasks.cleanup.*': {'queue': 'low'},
}
```

---

## ğŸ“ˆ Monitoring ve Health Checks

### Flower Dashboard

```bash
# Flower UI'a eriÅŸ
http://localhost:5555

# GÃ¶rebilecekleriniz:
- Active/completed/failed tasks
- Worker durumu (online/offline)
- Queue uzunluklarÄ±
- Task execution times
- Retry statistikleri
```

### Programmatic Health Check

```python
from app.utils.monitoring import health_check, get_current_metrics

# Health status
status = health_check()
# {
#   'status': 'healthy',
#   'uptime_seconds': 3600,
#   'success_rate': 95.5,
#   'tasks': {...},
#   'queues': {...}
# }

# Current metrics
metrics = get_current_metrics()
# {
#   'tasks_completed': 1500,
#   'tasks_failed': 80,
#   'active_tasks': 25,
#   ...
# }
```

---

## ğŸ§ª Load Testing

### 1000 KullanÄ±cÄ± SimÃ¼lasyonu

```bash
# Test script'i Ã§alÄ±ÅŸtÄ±r
cd tests
python load_test.py

# Test parametreleri (load_test.py'de):
TEST_USERS_COUNT = 1000          # 1000 kullanÄ±cÄ±
CONCURRENT_UPLOADS = 50          # 50'ÅŸer batch'ler halinde
TEST_AUDIO_FILE = "test_audio.mp3"  # Test dosyasÄ±

# SonuÃ§lar:
- Login success rate
- Upload success rate
- Transcription completion rate
- Average upload time
- Throughput (uploads/second)
```

### Beklenen Performans (1000 User)

```
âœ… Hedef Metrikler:
- Login Success: > 95%
- Upload Success: > 90%
- Transcription Completion: > 85%
- Upload Time: < 5 saniye
- Throughput: > 10 upload/saniye
```

---

## ğŸ”§ Configuration Ã–zeti

### Development (Local)

```python
# app/config/development.py
worker_concurrency = 2           # Hafif
worker_pool = 'solo'             # Debugging kolay
worker_autoscale = None          # Fixed concurrency
```

### Staging (Test)

```python
# app/config/staging.py
worker_concurrency = 4
worker_pool = 'prefork'          # Multi-process
worker_autoscale = (6, 2)        # Dynamic: 2-6 workers
```

### Production (1000+ Users)

```python
# app/config/production.py
worker_concurrency = 8
worker_pool = 'prefork'
worker_autoscale = (12, 4)       # Dynamic: 4-12 workers
worker_prefetch_multiplier = 4   # High throughput
worker_max_tasks_per_child = 1000  # Restart after 1000 tasks
```

---

## ğŸ“ KullanÄ±m Ã–rnekleri

### Backend'den Task Trigger Etme

```python
# Critical priority task (upload)
from app.workers.tasks.critical import validate_file_task
result = validate_file_task.delay(file_id, file_path)

# High priority task (transcription)
from app.workers.tasks.high_priority import process_transcription
result = process_transcription.delay(transcription_id, user_id)

# Default priority task (AI enhancement)
from app.workers.tasks.default_priority import enhance_text_task
result = enhance_text_task.delay(transcription_id, text, 'gemini', 'gemini-2.0-flash-lite')

# Low priority task (cleanup)
from app.workers.tasks.low_priority import cleanup_temp_files_task
result = cleanup_temp_files_task.delay()
```

### Task Status KontrolÃ¼

```python
# Task result'Ä± al
task_id = result.id
result_data = result.get(timeout=60)

# Task durumu kontrol et
if result.ready():
    print("Task completed")
elif result.failed():
    print("Task failed")
else:
    print("Task still processing")
```

---

## ğŸ” GÃ¼venlik Kontrol Listesi

Production'a geÃ§meden Ã¶nce:

- [ ] `.env.production` dosyasÄ±nda SECRET_KEY deÄŸiÅŸtirildi
- [ ] REDIS_PASSWORD gÃ¼Ã§lÃ¼ ÅŸifre ile ayarlandÄ±
- [ ] Database ÅŸifresi gÃ¼venli
- [ ] API keys production credentials ile deÄŸiÅŸtirildi
- [ ] CORS_ORIGINS production URLs ile gÃ¼ncellendi
- [ ] STORAGE_SECURE=True (SSL aktif)
- [ ] FLOWER_PASSWORD gÃ¼Ã§lÃ¼ ÅŸifre
- [ ] Firewall kurallarÄ± yapÄ±landÄ±rÄ±ldÄ±
- [ ] SSL sertifikasÄ± kuruldu
- [ ] Log rotation yapÄ±landÄ±rÄ±ldÄ±
- [ ] Backup stratejisi oluÅŸturuldu

---

## ğŸ“š DokÃ¼mantasyon

- **DetaylÄ± Deployment**: [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md)
- **API Documentation**: `/docs` endpoint (FastAPI Swagger)
- **Monitoring**: Flower UI (http://server:5555)
- **Health Check**: `/health` endpoint

---

## ğŸ†˜ HÄ±zlÄ± Troubleshooting

### Workers Ã§alÄ±ÅŸmÄ±yor
```bash
# Worker loglarÄ±nÄ± kontrol et
docker-compose -f docker-compose.prod.yml logs -f celery_worker_high

# Redis baÄŸlantÄ±sÄ±nÄ± test et
redis-cli -h localhost -p 6379 ping
```

### Task'lar queue'da bekliyor
```bash
# Queue durumunu kontrol
celery -A app.celery_app inspect active_queues

# Worker sayÄ±sÄ±nÄ± artÄ±r
docker-compose -f docker-compose.prod.yml up -d --scale celery_worker_high=10
```

### Memory kullanÄ±mÄ± yÃ¼ksek
```bash
# Resource kullanÄ±mÄ±
docker stats

# Ã‡Ã¶zÃ¼m: config/production.py'de
worker_max_tasks_per_child = 500  # Daha sÄ±k restart
```

---

## ğŸ“ Sonraki AdÄ±mlar

1. **Development Test**: Local'de test edin
   ```bash
   docker-compose -f docker-compose.dev.yml up
   ```

2. **Load Test**: 1000 kullanÄ±cÄ± simÃ¼lasyonu
   ```bash
   cd tests && python load_test.py
   ```

3. **Staging Deploy**: Test ortamÄ±nda deneyin
   ```bash
   ENVIRONMENT=staging docker-compose -f docker-compose.prod.yml up
   ```

4. **Production Deploy**: CanlÄ±ya alÄ±n
   ```bash
   # .env.production'Ä± dÃ¼zenle
   docker-compose -f docker-compose.prod.yml up -d
   ```

5. **Monitor**: Flower UI ve health checks ile takip edin
   ```bash
   # Flower: http://server:5555
   # Health: http://server:8002/health
   ```

---

**âœ… Sistem HazÄ±r!**

1000+ kullanÄ±cÄ± iÃ§in Ã¶lÃ§eklenebilir, production-ready mimari oluÅŸturuldu.

**Kapasite**:
- ğŸš€ 122 concurrent workers
- âš¡ Priority-based routing
- ğŸ“Š Real-time monitoring
- ğŸ”„ Auto-scaling ready
- ğŸ›¡ï¸ Production-grade security

**Ä°letiÅŸim**: SorularÄ±nÄ±z iÃ§in DEPLOYMENT_GUIDE.md'ye bakÄ±n.
