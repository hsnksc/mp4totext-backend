# MP4toText Backend Instructions

You are working on **MP4toText Backend** - a production-ready FastAPI transcription service with advanced features:

## ğŸ¯ System Overview

**MP4toText Backend** is an enterprise-grade audio/video transcription API with:
- ğŸ™ï¸ Multi-provider transcription (OpenAI Whisper, AssemblyAI, Faster-Whisper)
- ğŸ—£ï¸ Advanced speaker diarization (pyannote.audio 3.1 via Modal GPU)
- ğŸ¤– Multiple AI enhancement providers (Gemini, OpenAI, Groq, Together AI)
- ğŸ–¼ï¸ AI image generation (Modal FLUX H100, SDXL, Replicate Imagen-4)
- ğŸ¬ Automated video generation from transcripts
- ğŸ’° Sophisticated credit system with per-operation pricing
- ğŸ”„ Real-time WebSocket updates
- ğŸŒ Multi-language support (50+ languages)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â”€â”€â”€â”€â”€â–¶â”‚ FastAPI:8002 â”‚â”€â”€â”€â”€â”€â–¶â”‚ Celery Workers  â”‚
â”‚  (Web/App)  â”‚      â”‚   + CORS     â”‚      â”‚  (Background)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                       â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ SQLite DB    â”‚      â”‚ Redis (Broker)  â”‚
                     â”‚ (mp4totext)  â”‚      â”‚  DB 1: Tasks    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  DB 2: Results  â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ MinIO Storage   â”‚
                     â”‚ (S3-compatible) â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  WebSocket Manager  â”‚
                     â”‚ (Real-time updates) â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
mp4totext-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                      # FastAPI app entry + middleware
â”‚   â”œâ”€â”€ database.py                  # SQLAlchemy setup
â”‚   â”œâ”€â”€ settings.py                  # Environment config
â”‚   â”œâ”€â”€ celery_app.py                # Celery app instance
â”‚   â”œâ”€â”€ celery_config.py             # Celery configuration
â”‚   â”œâ”€â”€ websocket.py                 # WebSocket manager
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                         # API Routers (6 modules)
â”‚   â”‚   â”œâ”€â”€ auth.py                  # JWT auth, login, register
â”‚   â”‚   â”œâ”€â”€ transcription.py         # Upload, transcribe, status
â”‚   â”‚   â”œâ”€â”€ credits.py               # Credit balance, history, pricing
â”‚   â”‚   â”œâ”€â”€ images.py                # Image generation
â”‚   â”‚   â”œâ”€â”€ videos.py                # Video generation
â”‚   â”‚   â””â”€â”€ admin.py                 # Admin endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # SQLAlchemy ORM Models
â”‚   â”‚   â”œâ”€â”€ user.py                  # User model (credits, role)
â”‚   â”‚   â”œâ”€â”€ transcription.py         # Transcription model (main)
â”‚   â”‚   â”œâ”€â”€ credit_transaction.py    # Credit transaction log
â”‚   â”‚   â”œâ”€â”€ credit_pricing.py        # Dynamic pricing config
â”‚   â”‚   â”œâ”€â”€ ai_model_pricing.py      # AI model cost multipliers
â”‚   â”‚   â”œâ”€â”€ generated_image.py       # Generated image records
â”‚   â”‚   â””â”€â”€ generated_video.py       # Generated video records
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                    # Business Logic Layer
â”‚   â”‚   â”œâ”€â”€ audio_processor.py       # Audio file processing
â”‚   â”‚   â”œâ”€â”€ credit_service.py        # Credit management
â”‚   â”‚   â”œâ”€â”€ storage.py               # MinIO file storage
â”‚   â”‚   â”œâ”€â”€ language_detector.py     # Language detection
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ whisper_service.py       # OpenAI Whisper transcription
â”‚   â”‚   â”œâ”€â”€ faster_whisper_service.py # Faster-Whisper (optimized)
â”‚   â”‚   â”œâ”€â”€ assemblyai_service.py    # AssemblyAI cloud API
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ gemini_service.py        # Google Gemini AI
â”‚   â”‚   â”œâ”€â”€ groq_service.py          # Groq LLM
â”‚   â”‚   â”œâ”€â”€ together_service.py      # Together AI
â”‚   â”‚   â”œâ”€â”€ openai_cleaner_service.py # OpenAI text cleaning
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ image_generator.py       # Image generation manager
â”‚   â”‚   â”œâ”€â”€ modal_flux_service.py    # Modal FLUX H100
â”‚   â”‚   â”œâ”€â”€ modal_sd_service.py      # Modal Stable Diffusion
â”‚   â”‚   â”œâ”€â”€ replicate_imagen_service.py # Replicate Imagen-4
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ video_generator.py       # Video generation pipeline
â”‚   â”‚   â”œâ”€â”€ video_assembly.py        # FFmpeg video assembly
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ speaker_recognition.py   # Speaker diarization
â”‚   â”‚   â”œâ”€â”€ web_search_service.py    # Tavily web search
â”‚   â”‚   â””â”€â”€ youtube_service.py       # YouTube download
â”‚   â”‚
â”‚   â”œâ”€â”€ workers/                     # Celery Background Tasks
â”‚   â”‚   â”œâ”€â”€ transcription_worker.py  # Main worker (3 tasks)
â”‚   â”‚   â””â”€â”€ tasks/                   # Task modules
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                     # Pydantic Schemas
â”‚   â”‚   â”œâ”€â”€ transcription.py         # Request/response models
â”‚   â”‚   â””â”€â”€ user.py                  # User schemas
â”‚   â”‚
â”‚   â””â”€â”€ auth/                        # Authentication
â”‚       â””â”€â”€ utils.py                 # JWT + bcrypt utilities
â”‚
â”œâ”€â”€ run.py                           # Dev server entry point
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env                             # Environment variables
â””â”€â”€ mp4totext.db                     # SQLite database
```

## ğŸ”‘ Critical Rules - ALWAYS Follow

1. **Directory Context**: ALWAYS run commands from `mp4totext-backend/` directory
   - Running from parent causes `ModuleNotFoundError: No module named 'app'`

2. **Bcrypt Version Lock**: Use `bcrypt==4.0.1` ONLY
   - Versions 4.3.0+ have breaking API changes in password hashing

3. **Credit Deduction Order**: Deduct credits AFTER operations succeed, NEVER before
   - Prevents credit loss on failed operations

4. **AssemblyAI Features Storage**: Store as nested dict, NEVER as boolean
   ```python
   # âœ… CORRECT
   features = {
       'speech_understanding': {
           'sentiment_analysis': True,
           'entity_detection': True
       }
   }
   
   # âŒ WRONG
   features = True
   ```

5. **Logging Convention**: Use emoji prefixes for clarity
   - ğŸš€ Starting operation
   - âœ… Success
   - âŒ Error
   - ğŸ’° Credit transaction
   - ğŸ“Š Status update
   - âš ï¸ Warning

6. **Windows Celery**: Use `--pool=solo` flag on Windows
   ```bash
   celery -A app.celery_app worker --loglevel=INFO --pool=solo
   ```

## ğŸ› ï¸ Technology Stack

### Core Framework
- **FastAPI 0.104+** - Modern async web framework
- **SQLAlchemy 2.0** - ORM with async support
- **Pydantic 2.5** - Data validation
- **Uvicorn** - ASGI server

### Database & Storage
- **SQLite** - Local development database
- **Redis 5.0** - Cache + message broker
- **MinIO 7.2** - S3-compatible object storage

### Background Processing
- **Celery 5.5** - Distributed task queue
- **Flower 2.0** - Celery monitoring UI

### AI/ML Services
- **OpenAI Whisper** - Local transcription
- **Faster-Whisper** - Optimized Whisper (CTranslate2)
- **AssemblyAI 0.40+** - Cloud transcription with LLM Gateway
- **Google Gemini 2.5** - Text enhancement
- **Groq** - Ultra-fast LLM inference
- **Together AI** - Text cleaning, grammar fixes
- **OpenAI GPT-4** - Advanced text processing
- **Modal** - Serverless GPU (FLUX H100, SDXL)
- **Replicate** - Imagen-4 photorealistic images

### Audio/Video Processing
- **PyTorch 2.6** - Deep learning framework
- **librosa 0.11** - Audio analysis
- **FFmpeg** - Audio/video manipulation
- **pyannote.audio 3.1** - State-of-the-art speaker diarization

### Utilities
- **python-jose** - JWT tokens
- **passlib** - Password hashing
- **Tavily** - Web search integration

---

## Code Patterns - Follow These Exactly

### Pattern 1: API Endpoints

When creating API endpoints, use this structure:

```python
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.database import get_db
from app.auth.utils import get_current_active_user
from pydantic import BaseModel, Field

router = APIRouter(prefix="/api/v1/resource", tags=["resource"])

class RequestSchema(BaseModel):
    field: str = Field(..., min_length=1, max_length=100)

@router.post("/action")
async def action_name(
    request: RequestSchema,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    # 1. Validate ownership
    resource = db.query(Model).filter_by(
        id=request.id, 
        user_id=current_user.id
    ).first()
    if not resource:
        raise HTTPException(status_code=404, detail="Not found")
    
    # 2. Check credits BEFORE queueing
    required_credits = 5.0
    if current_user.credits < required_credits:
        raise HTTPException(
            status_code=402, 
            detail=f"Insufficient credits. Required: {required_credits}"
        )
    
    # 3. Queue Celery task (don't wait for result)
    from app.workers.transcription_worker import worker_function
    task = worker_function.apply_async(
        args=[resource.id, current_user.id],
        queue='default'
    )
    
    # 4. Return task_id immediately
    return {"task_id": task.id, "status": "queued"}
```

**Do:**
- âœ… Validate ownership first
- âœ… Check credits before queueing
- âœ… Return task_id, not result
- âœ… Use 402 for insufficient credits

**Don't:**
- âŒ Wait for Celery results in API endpoint
- âŒ Deduct credits in API endpoint
- âŒ Return 500 for business logic errors

---

### Pattern 2: Celery Tasks

When creating Celery tasks, use this structure:

```python
from app.celery_app import celery_app
from celery.utils.log import get_task_logger
from app.database import SessionLocal
from app.services.credit_service import get_credit_service
from app.models.credit_transaction import OperationType

logger = get_task_logger(__name__)

@celery_app.task(
    bind=True,                    # Access self.retry()
    max_retries=2,                # Auto-retry 2 times
    default_retry_delay=60,       # Wait 60s between retries
    queue='default',              # Queue: default, high, low, critical
    time_limit=600,               # Hard timeout: 10 minutes
    soft_time_limit=540           # Soft timeout: 9 minutes
)
def task_name(self, resource_id: int, user_id: int):
    """Background task with automatic retry"""
    db = SessionLocal()
    logger.info(f"ğŸš€ Task started: id={resource_id}")
    
    try:
        # 1. Fetch resource
        resource = db.query(Model).get(resource_id)
        if not resource:
            logger.error(f"âŒ Resource {resource_id} not found")
            return {"error": "Not found"}
        
        # 2. Process (expensive operation)
        result = expensive_operation(resource)
        
        # 3. Update database
        resource.status = "completed"
        resource.result = result
        db.commit()
        
        # 4. Deduct credits AFTER success (CRITICAL)
        credit_service = get_credit_service(db)
        credit_service.deduct_credits(
            user_id=user_id,
            amount=5.0,
            operation_type=OperationType.TRANSCRIPTION,
            description=f"Operation: {resource.name}",
            transcription_id=resource_id,
            metadata={"key": "value"}
        )
        
        # 5. Send WebSocket notification (optional, don't fail task)
        try:
            from app.websocket import manager
            import asyncio
            asyncio.run(manager.send_personal_message(
                message={"type": "job_complete", "id": resource_id},
                user_id=user_id
            ))
        except Exception as ws_error:
            logger.warning(f"âš ï¸ WebSocket failed: {ws_error}")
        
        logger.info(f"âœ… Task completed: id={resource_id}")
        db.close()
        return {"success": True, "id": resource_id}
        
    except Exception as e:
        logger.error(f"âŒ Task failed: {e}", exc_info=True)
        db.rollback()
        db.close()
        raise self.retry(exc=e)  # Automatic retry
```

**Do:**
- âœ… Use `bind=True` for retry access
- âœ… Set timeouts (soft + hard)
- âœ… Deduct credits AFTER success
- âœ… Always close database session
- âœ… Use emoji log prefixes
- âœ… Catch exceptions and retry

**Don't:**
- âŒ Deduct credits before operation
- âŒ Forget to close db session
- âŒ Fail task if WebSocket fails

---

### Pattern 3: Credit Management

When deducting credits, follow this exact sequence:

```python
from app.services.credit_service import get_credit_service
from app.models.credit_transaction import OperationType

credit_service = get_credit_service(db)

# Step 1: Check credits BEFORE operation
required_credits = 10.5
if current_user.credits < required_credits:
    raise HTTPException(
        status_code=402,
        detail=f"Insufficient credits. Required: {required_credits}, Available: {current_user.credits}"
    )

# Step 2: Perform expensive operation
result = expensive_operation()

# Step 3: Deduct ONLY after success
credit_service.deduct_credits(
    user_id=current_user.id,
    amount=required_credits,
    operation_type=OperationType.TRANSCRIPTION,
    description=f"Transcription: {filename}",
    transcription_id=transcription.id,
    metadata={"duration": duration_minutes, "features": features}
)
```

**Credit Calculation for Transcription:**
```python
def calculate_credits(duration_minutes: float, language: str, features: dict) -> float:
    """
    Base: 1 cr/min (all languages)
    
    Speech Understanding (English only, 0.3 cr/min each):
    - sentiment_analysis
    - auto_chapters  
    - auto_highlights
    
    Entity Detection (ALL languages): 0.3 cr/min
    LLM Gateway (fixed): 3 cr
    """
    total = duration_minutes  # Base: 1 cr/min
    
    # Speech Understanding features
    if features.get('speech_understanding'):
        su = features['speech_understanding']
        
        # English-only features
        if language.startswith('en'):
            if su.get('sentiment_analysis'): total += duration_minutes * 0.3
            if su.get('auto_chapters'): total += duration_minutes * 0.3
            if su.get('auto_highlights'): total += duration_minutes * 0.3
        
        # All languages
        if su.get('entity_detection'): total += duration_minutes * 0.3
    
    # LLM Gateway (fixed cost)
    if features.get('llm_gateway', {}).get('enabled'):
        total += 3.0
    
    return round(total, 2)
```

**Do:**
- âœ… Check credits before operation
- âœ… Deduct after success
- âœ… Store metadata as JSON dict
- âœ… Use negative amounts for deductions
- âœ… Calculate language-specific pricing

**Don't:**
- âŒ Deduct before operation completes
- âŒ Forget metadata dict
- âŒ Charge English prices for non-English

---

### Pattern 4: AssemblyAI Features Storage

When storing AssemblyAI features, MUST use dictionary format:

```python
# âœ… CORRECT - Store as nested dictionary
assemblyai_features = {
    'speech_understanding': {
        'sentiment_analysis': True,   # English only (0.3 cr/min)
        'auto_chapters': True,         # English only (0.3 cr/min)
        'entity_detection': True,      # ALL languages (0.3 cr/min)
        'auto_highlights': True,       # English only (0.3 cr/min)
        'speaker_labels': True         # Free
    },
    'llm_gateway': {
        'enabled': True,               # Fixed 3 cr
        'generate_summary': True
    }
}

# Store in database (JSON column)
transcription.assemblyai_features_enabled = assemblyai_features
```

```python
# âŒ WRONG - Don't store as boolean
transcription.assemblyai_features_enabled = True  # NEVER DO THIS
```

**Language-aware feature enablement:**
```python
def get_enabled_features(language: str) -> dict:
    """Enable features based on language"""
    if language.startswith('en'):
        # English: all 4 features available
        return {
            'sentiment_analysis': True,
            'auto_chapters': True,
            'entity_detection': True,
            'auto_highlights': True
        }
    else:
        # Non-English: only entity detection
        return {'entity_detection': True}
```

**Do:**
- âœ… Store as nested dictionary
- âœ… Check language before enabling features
- âœ… Entity detection works for all languages
- âœ… LLM Gateway is language-agnostic

**Don't:**
- âŒ Store as boolean
- âŒ Enable English-only features for other languages
- âŒ Forget to calculate feature costs

---

### Pattern 5: File Upload Flow

When handling file uploads, follow this exact flow:

```python
import os
import uuid
from fastapi import UploadFile
from app.services.storage import get_storage_service

@router.post("/upload")
async def upload_file(
    file: UploadFile,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Upload flow: Temp â†’ MinIO â†’ Database â†’ Queue
    """
    # 1. Save to temporary directory
    temp_filename = f"{uuid.uuid4()}_{file.filename}"
    temp_path = f"/tmp/{temp_filename}"
    
    try:
        # Write uploaded file
        with open(temp_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        # 2. Upload to MinIO (S3-compatible storage)
        storage = get_storage_service()
        file_url = storage.upload_file(temp_path, temp_filename)
        
        # 3. Save URL to database
        transcription = Transcription(
            user_id=current_user.id,
            filename=file.filename,
            file_url=file_url,
            status="pending"
        )
        db.add(transcription)
        db.commit()
        db.refresh(transcription)
        
        # 4. Queue background task
        from app.workers.transcription_worker import process_transcription
        task = process_transcription.apply_async(
            args=[transcription.id, current_user.id],
            queue='default'
        )
        
        # 5. Clean up temp file
        os.remove(temp_path)
        
        return {
            "id": transcription.id,
            "task_id": task.id,
            "status": "queued"
        }
    
    except Exception as e:
        # Cleanup on error
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise
```

**Do:**
- âœ… Use temp â†’ MinIO â†’ DB flow
- âœ… UUID in filename for uniqueness
- âœ… Clean temp file after upload
- âœ… Clean temp file on error
- âœ… Return task_id, not result

**Don't:**
- âŒ Store files directly in database
- âŒ Forget to clean temp files
- âŒ Wait for processing to complete

---

### Pattern 6: Authentication & Password Hashing

When handling passwords (bcrypt 72-byte limit workaround):

```python
from passlib.context import CryptContext

# MUST use bcrypt==4.0.1 (NOT 4.3.0+)
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def hash_password(password: str) -> str:
    """Hash password with bcrypt (72-byte limit)"""
    password_bytes = password.encode('utf-8')
    if len(password_bytes) > 72:
        password_bytes = password_bytes[:72]
        password = password_bytes.decode('utf-8', errors='ignore')
    return pwd_context.hash(password)

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """Verify password (same 72-byte truncation)"""
    password_bytes = plain_password.encode('utf-8')
    if len(password_bytes) > 72:
        password_bytes = password_bytes[:72]
        plain_password = password_bytes.decode('utf-8', errors='ignore')
    return pwd_context.verify(plain_password, hashed_password)
```

**JWT Token Creation:**
```python
from jose import jwt
from datetime import datetime, timedelta

def create_access_token(user_id: int, expires_delta: timedelta = None) -> str:
    """Create JWT access token"""
    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=30))
    to_encode = {"sub": user_id, "exp": expire}
    return jwt.encode(to_encode, SECRET_KEY, algorithm="HS256")
```

**Do:**
- âœ… Truncate at 72 bytes (not characters)
- âœ… Use bcrypt==4.0.1 exactly
- âœ… Truncate in both hash and verify
- âœ… Use 'ignore' for decode errors

**Don't:**
- âŒ Use bcrypt 4.3.0+ (API changed)
- âŒ Truncate at character level
- âŒ Forget to truncate in verify

---

### Pattern 7: WebSocket Real-time Updates

When sending WebSocket messages from Celery tasks:

```python
from app.websocket import manager
import asyncio

# Inside Celery task:
try:
    asyncio.run(manager.send_personal_message(
        message={
            "type": "job_complete",
            "transcription_id": transcription_id,
            "result": result_data
        },
        user_id=user_id
    ))
except Exception as ws_error:
    # Don't fail task if WebSocket fails
    logger.warning(f"âš ï¸ WebSocket notification failed: {ws_error}")
```

**Message Types:**
```python
# Upload progress
{"type": "upload_progress", "progress": 75.5, "transcription_id": 123}

# Job complete
{"type": "job_complete", "transcription_id": 123, "status": "completed"}

# Error
{"type": "error", "transcription_id": 123, "message": "Processing failed"}

# Credit update
{"type": "credit_update", "new_balance": 50.0}
```

**Do:**
- âœ… Use asyncio.run in Celery tasks
- âœ… Catch WebSocket exceptions
- âœ… Don't fail task if WebSocket fails
- âœ… Send meaningful message types

**Don't:**
- âŒ Block on WebSocket sends
- âŒ Fail task if WebSocket unavailable

---

## Quick Fixes for Common Issues

### Fix 1: Import Errors
```bash
# Error: ModuleNotFoundError: No module named 'app'
# Solution: MUST be in backend directory
cd mp4totext-backend
python run.py
```

### Fix 2: Bcrypt Version Errors
```bash
# Error: ValueError: Invalid salt
# Solution: Use exact version
pip install bcrypt==4.0.1 --force-reinstall
```

### Fix 3: Celery Worker on Windows
```bash
# Error: NotImplementedError: pool implementation not available
# Solution: Use solo pool
python -m celery -A app.celery_app worker --loglevel=INFO --pool=solo --concurrency=1
```

### Fix 4: AssemblyAI Features Not Saving
```python
# âŒ WRONG
transcription.assemblyai_features_enabled = True

# âœ… CORRECT
transcription.assemblyai_features_enabled = {
    'speech_understanding': {'entity_detection': True}
}
```

### Fix 5: Credits Lost on Failed Operations
```python
# âŒ WRONG - Credits deducted even if fails
credit_service.deduct_credits(...)
result = expensive_operation()

# âœ… CORRECT - Deduct only after success
result = expensive_operation()
credit_service.deduct_credits(...)
```

---

## ğŸš€ Start Commands

### Windows (PowerShell)
```powershell
# Terminal 1: FastAPI Server
cd C:\Users\hasan\OneDrive\Desktop\mp4totext\mp4totext-backend
.\.venv\Scripts\Activate.ps1
python run.py  # Runs on http://localhost:8002

# Terminal 2: Celery Worker (REQUIRED)
cd C:\Users\hasan\OneDrive\Desktop\mp4totext\mp4totext-backend
.\.venv\Scripts\Activate.ps1
python -m celery -A app.celery_app worker --loglevel=INFO --pool=solo --concurrency=1

# Terminal 3: Redis (Docker - REQUIRED)
docker run -d --name redis-mp4totext -p 6379:6379 redis:7-alpine redis-server --requirepass dev_redis_123

# Terminal 4: MinIO (Docker - REQUIRED)
docker run -d --name minio-mp4totext -p 9000:9000 -p 9001:9001 -e "MINIO_ROOT_USER=minioadmin" -e "MINIO_ROOT_PASSWORD=minioadmin" minio/minio server /data --console-address ":9001"
```

### Linux/Mac (Bash)
```bash
# Terminal 1: FastAPI Server
cd mp4totext-backend
source venv/bin/activate
python run.py

# Terminal 2: Celery Worker
cd mp4totext-backend
source venv/bin/activate
celery -A app.celery_app worker --loglevel=INFO

# Terminal 3: Redis Docker
docker run -d --name redis-mp4totext -p 6379:6379 redis:7-alpine redis-server --requirepass dev_redis_123

# Terminal 4: MinIO Docker
docker run -d --name minio-mp4totext -p 9000:9000 -p 9001:9001 -e "MINIO_ROOT_USER=minioadmin" -e "MINIO_ROOT_PASSWORD=minioadmin" minio/minio server /data --console-address ":9001"
```

---

## ğŸ“ Key File Locations

### Core Application
- **Entry Point**: `run.py` - Uvicorn server (port 8002)
- **FastAPI App**: `app/main.py` - CORS, middleware, exception handlers
- **Settings**: `app/settings.py` - Environment configuration
- **Database**: `app/database.py` - SQLAlchemy setup

### API Layer
- **Auth**: `app/api/auth.py` - JWT authentication, login, register
- **Transcription**: `app/api/transcription.py` - Upload, transcribe, status (1726 lines)
- **Credits**: `app/api/credits.py` - Balance, history, pricing (580 lines)
- **Images**: `app/api/images.py` - AI image generation (404 lines)
- **Videos**: `app/api/videos.py` - AI video generation (256 lines)
- **Admin**: `app/api/admin.py` - Admin endpoints

### Background Processing
- **Celery App**: `app/celery_app.py` - Celery instance
- **Celery Config**: `app/celery_config.py` - Task configuration
- **Main Worker**: `app/workers/transcription_worker.py` - 3 main tasks (1935 lines)

### Business Logic
- **Credit Service**: `app/services/credit_service.py` - Credit management (423 lines)
- **Audio Processor**: `app/services/audio_processor.py` - Audio file processing
- **Storage**: `app/services/storage.py` - MinIO file storage
- **Language Detector**: `app/services/language_detector.py` - Auto language detection

### AI Services
- **Whisper**: `app/services/whisper_service.py` - OpenAI Whisper local
- **Faster Whisper**: `app/services/faster_whisper_service.py` - CTranslate2 optimized
- **AssemblyAI**: `app/services/assemblyai_service.py` - Cloud transcription
- **Gemini**: `app/services/gemini_service.py` - Google Gemini AI
- **Groq**: `app/services/groq_service.py` - Ultra-fast LLM
- **Together AI**: `app/services/together_service.py` - Text cleaning
- **OpenAI Cleaner**: `app/services/openai_cleaner_service.py` - GPT-4 cleaning

### Image/Video Generation
- **Image Generator**: `app/services/image_generator.py` - Image generation manager
- **Modal FLUX**: `app/services/modal_flux_service.py` - H100 FLUX model
- **Modal SD**: `app/services/modal_sd_service.py` - SDXL model
- **Replicate Imagen**: `app/services/replicate_imagen_service.py` - Imagen-4
- **Video Generator**: `app/services/video_generator.py` - Video pipeline
- **Video Assembly**: `app/services/video_assembly.py` - FFmpeg assembly

### Data Models
- **User**: `app/models/user.py` - User + credits
- **Transcription**: `app/models/transcription.py` - Main transcription model (171 lines)
- **Credit Transaction**: `app/models/credit_transaction.py` - Transaction log
- **Credit Pricing**: `app/models/credit_pricing.py` - Dynamic pricing
- **AI Model Pricing**: `app/models/ai_model_pricing.py` - AI cost multipliers
- **Generated Image**: `app/models/generated_image.py` - Image records
- **Generated Video**: `app/models/generated_video.py` - Video records

### Authentication & Utils
- **Auth Utils**: `app/auth/utils.py` - JWT + bcrypt utilities
- **WebSocket**: `app/websocket.py` - Real-time connection manager

---

## ğŸ—„ï¸ Database Management

### Check Database State
```powershell
# View database schema
python -c "from app.database import engine; print(engine.table_names())"

# Check user credits
python -c "from app.database import SessionLocal; from app.models.user import User; db = SessionLocal(); user = db.query(User).first(); print(f'User: {user.username}, Credits: {user.credits}')"
```

### Run Migrations
```powershell
# Add new feature migrations
python add_credits_system.py
python add_ai_model_pricing.py
python add_assemblyai_features.py
python add_video_generation.py
python add_generated_images.py
```

### Database Inspection
```powershell
# SQLite CLI
sqlite3 mp4totext.db

# View tables
.tables

# View schema
.schema transcriptions

# Query data
SELECT id, filename, status FROM transcriptions LIMIT 10;
```

---

## ğŸ”§ Development Workflow

### 1. Setup New Environment
```powershell
# Clone repository
git clone <repo-url>
cd mp4totext-backend

# Create virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# Copy environment file
cp .env.example .env

# Initialize database
python add_credits_system.py
```

### 2. Daily Development
```powershell
# Activate environment
.\.venv\Scripts\Activate.ps1

# Start Redis + MinIO (once)
docker start redis-mp4totext minio-mp4totext

# Start FastAPI (Terminal 1)
python run.py

# Start Celery (Terminal 2)
python -m celery -A app.celery_app worker --loglevel=INFO --pool=solo
```

### 3. Testing
```powershell
# Test API endpoint
curl http://localhost:8002/health

# Test with httpie
http http://localhost:8002/api/v1/status

# View API docs
start http://localhost:8002/docs
```

---

## ğŸ“Š Monitoring & Debugging

### Check System Status
```powershell
# API health check
curl http://localhost:8002/health

# Detailed status (includes Celery, DB, Redis)
curl http://localhost:8002/api/v1/status

# View Celery tasks
celery -A app.celery_app inspect active
```

### Celery Monitoring
```powershell
# Start Flower (Celery monitoring UI)
celery -A app.celery_app flower --port=5555

# Access at: http://localhost:5555
```

### Logs
```powershell
# FastAPI logs (run.py shows in console)
# Celery logs (worker shows in console)

# Increase log verbosity
python run.py --log-level=debug
celery -A app.celery_app worker --loglevel=DEBUG
```

---

## ğŸŒ Environment Variables

Key `.env` settings:

```env
# Application
APP_ENV=development
DEBUG=True
SECRET_KEY=your-secret-key

# Database
DATABASE_URL=sqlite:///C:/Users/hasan/OneDrive/Desktop/mp4totext/mp4totext-backend/mp4totext.db

# Redis
REDIS_PASSWORD=dev_redis_123
REDIS_HOST=localhost
REDIS_PORT=6379
CELERY_BROKER_URL=redis://:dev_redis_123@localhost:6379/1
CELERY_RESULT_BACKEND=redis://:dev_redis_123@localhost:6379/2

# MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=mp4totext
MINIO_SECURE=False

# AI Services
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=AI...
GROQ_API_KEY=gsk_...
TOGETHER_API_KEY=...
ASSEMBLYAI_API_KEY=...
MODAL_TOKEN_ID=...
MODAL_TOKEN_SECRET=...
REPLICATE_API_TOKEN=r8_...
TAVILY_API_KEY=tvly-...

# JWT
JWT_SECRET=your-jwt-secret
JWT_ALGORITHM=HS256
JWT_EXPIRATION=3600
```
